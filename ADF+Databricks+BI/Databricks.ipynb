{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f226e562",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "dbutils.fs.mount(\n",
    "  source = \"wasbs://retail@retailproject.blob.core.windows.net\",\n",
    "  mount_point = \"/mnt/retail_project\",\n",
    "  extra_configs = {\"fs.azure.account.key.retailproject.blob.core.windows.net\":\"secret access key\"})\n",
    "\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "dbutils.fs.ls('/mnt/retail_project/bronze/transaction/')\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "# DBTITLE 1,read the bronze layer\n",
    "# Read raw data from Bronze layer\n",
    "df_transactions = spark.read.parquet('/mnt/retail_project/bronze/transaction/')\n",
    "df_products = spark.read.parquet('/mnt/retail_project/bronze/product/')\n",
    "df_stores = spark.read.parquet('/mnt/retail_project/bronze/store/')\n",
    "\n",
    "df_customers = spark.read.parquet('/mnt/retail_project/bronze/customer/manish040596/azure-data-engineer---multi-source/refs/heads/main/')\n",
    "display(df_customers)\n",
    "\n",
    "\n",
    "display(df_transactions)\n",
    "\n",
    "# DBTITLE 1,create silver layer - data cleaning\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Convert types and clean data\n",
    "df_transactions = df_transactions.select(\n",
    "    col(\"transaction_id\").cast(\"int\"),\n",
    "    col(\"customer_id\").cast(\"int\"),\n",
    "    col(\"product_id\").cast(\"int\"),\n",
    "    col(\"store_id\").cast(\"int\"),\n",
    "    col(\"quantity\").cast(\"int\"),\n",
    "    col(\"transaction_date\").cast(\"date\")\n",
    ")\n",
    "\n",
    "df_products = df_products.select(\n",
    "    col(\"product_id\").cast(\"int\"),\n",
    "    col(\"product_name\"),\n",
    "    col(\"category\"),\n",
    "    col(\"price\").cast(\"double\")\n",
    ")\n",
    "\n",
    "df_stores = df_stores.select(\n",
    "    col(\"store_id\").cast(\"int\"),\n",
    "    col(\"store_name\"),\n",
    "    col(\"location\")\n",
    ")\n",
    "\n",
    "df_customers = df_customers.select(\n",
    "    \"customer_id\", \"first_name\", \"last_name\", \"email\", \"city\", \"registration_date\"\n",
    ").dropDuplicates([\"customer_id\"])\n",
    "\n",
    "\n",
    "# DBTITLE 1,join all data together\n",
    "# Join all data\n",
    "df_silver = df_transactions \\\n",
    "    .join(df_customers, \"customer_id\") \\\n",
    "    .join(df_products, \"product_id\") \\\n",
    "    .join(df_stores, \"store_id\") \\\n",
    "    .withColumn(\"total_amount\", col(\"quantity\") * col(\"price\"))\n",
    "\n",
    "\n",
    "display(df_silver)\n",
    "\n",
    "# DBTITLE 1,dump to adls location\n",
    "silver_path = \"/mnt/retail_project/silver/\"\n",
    "\n",
    "df_silver.write.mode(\"overwrite\").format(\"delta\").save(silver_path)\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# DBTITLE 1,create silver dataset\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE retail_silver_cleaned\n",
    "USING DELTA\n",
    "LOCATION '/mnt/retail_project/silver/'\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "# MAGIC \n",
    "%sql \n",
    "select * from retail_silver_cleaned\n",
    "\n",
    "# DBTITLE 1,gold layer\n",
    "# Load cleaned transactions from Silver layer\n",
    "silver_df = spark.read.format(\"delta\").load(\"/mnt/retail_project/silver/\")\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "display(silver_df)\n",
    "\n",
    "from pyspark.sql.functions import sum, countDistinct, avg\n",
    "\n",
    "gold_df = silver_df.groupBy(\n",
    "    \"transaction_date\",\n",
    "    \"product_id\", \"product_name\", \"category\",\n",
    "    \"store_id\", \"store_name\", \"location\"\n",
    ").agg(\n",
    "    sum(\"quantity\").alias(\"total_quantity_sold\"),\n",
    "    sum(\"total_amount\").alias(\"total_sales_amount\"),\n",
    "    countDistinct(\"transaction_id\").alias(\"number_of_transactions\"),\n",
    "    avg(\"total_amount\").alias(\"average_transaction_value\")\n",
    ")\n",
    "\n",
    "display(gold_df)\n",
    "\n",
    "# COMMAND ----------\n",
    "gold_path = \"/mnt/retail_project/gold/\"\n",
    "\n",
    "gold_df.write.mode(\"overwrite\").format(\"delta\").save(gold_path)\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE retail_gold_sales_summary\n",
    "USING DELTA\n",
    "LOCATION '/mnt/retail_project/gold/' \"\"\")\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "select * from retail_gold_sales_summary\n",
    "\n",
    "# COMMAND ----------"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
